{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from geoalchemy2 import Geometry, WKTElement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Uploading Data to pgAdmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the section below, we are cleaning all our files including:\n",
    "1.  Neighbourhoods.csv\n",
    "2.  BusinessStats.csv\n",
    "3.  StatisticalAreas.csv\n",
    "4.  RFSNSW_BFPL.shp\n",
    "5.  SA2_2016_AUST.shp\n",
    "6.  RFSStation_EPSG4326.json (additional dataset)\n",
    "\n",
    "Methods for cleaning data includes:\n",
    "\n",
    "- checkNull(dataset, beenCleaned): check if there's a null value\n",
    "- removeNull(dataset): drop the null value in the dataset\n",
    "\n",
    "** For each dataset, we also check the type of different columns to see if they are in their correct type. If they're not, then we convert them. For instance, all population values are intially string, but we convert them into numeric values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function use to check if null values exist in the dataset. If there's null value, we'll drop the row to increase \n",
    "# accuracy in our calculations.\n",
    "\n",
    "def checkNull( dataset ):\n",
    "    \n",
    "    beenCleaned = False    \n",
    "    \n",
    "    for num in list(dataset.isnull().sum()):\n",
    "\n",
    "        if num != 0:\n",
    "            print(\"THIS DATASET HAS SOME NA VALUES.\")\n",
    "            print(\"Null value found. Coverted null values to ...\")\n",
    "            dataset = dataset.dropna() #found null, drop the row\n",
    "            beenCleaned = True\n",
    "            \n",
    "    if beenCleaned:\n",
    "        print(\"\\nNull values have been removed. You're good to go!\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nNo null values in. Good to go, no need for cleaning :)\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning StatisticalAreas.csv and Uploading it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No null values in. Good to go, no need for cleaning :)\n",
      "     area_id                          area_name  parent_area_id\n",
      "0          1                    New South Wales               0\n",
      "1         10                     Greater Sydney               1\n",
      "2         11                        Rest of NSW               1\n",
      "3          2                           Victoria               0\n",
      "4         20                  Greater Melbourne               2\n",
      "..       ...                                ...             ...\n",
      "429      106        Hunter Valley exc Newcastle              11\n",
      "430    11102              Lake Macquarie - West             111\n",
      "431      111       Newcastle and Lake Macquarie              11\n",
      "432    11402                 Southern Highlands             114\n",
      "433      114  Southern Highlands and Shoalhaven              11\n",
      "\n",
      "[434 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "rawData = pd.read_csv(\"StatisticalAreas.csv\")\n",
    "\n",
    "#Check if contains NULL\n",
    "cleanData = checkNull(rawData)\n",
    "\n",
    "#Cleaning data so that only numeric values are included in area_id\n",
    "if cleanData['area_id'].dtypes != int:\n",
    "    print(\"\\nUpdated area_id data type from \" + str(cleanData['area_id'].dtypes) + \" to integer & removed data with wrong type\")\n",
    "    cleanData = cleanData[cleanData.area_id.str.isnumeric()]\n",
    "    cleanData['area_id'].astype(int)\n",
    "\n",
    "#Cleaning data so that only numeric values are included in parent_area_id\n",
    "if cleanData['parent_area_id'].dtypes != int:\n",
    "    print(\"\\nUpdated area_id data type from \" + str(cleanData['parent_area_id'].dtypes) + \" to integer & removed data with wrong type\")\n",
    "    cleanData = cleanData[cleanData.parent_area_id.str.isnumeric()]\n",
    "    cleanData['parent_area_id'].astype(int)\n",
    "\n",
    "statisticalAreas_clean = cleanData\n",
    "\n",
    "\n",
    "print(cleanData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Uploading Neighbourhoods.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS DATASET HAS SOME NA VALUES.\n",
      "Null value found. Coverted null values to ...\n",
      "THIS DATASET HAS SOME NA VALUES.\n",
      "Null value found. Coverted null values to ...\n",
      "THIS DATASET HAS SOME NA VALUES.\n",
      "Null value found. Coverted null values to ...\n",
      "THIS DATASET HAS SOME NA VALUES.\n",
      "Null value found. Coverted null values to ...\n",
      "\n",
      "Null values have been removed. You're good to go!\n",
      "\n",
      "Commas in numeric data removed and all numbers as type string converted to numeric values!\n",
      "       area_id                    area_name   land_area  population  \\\n",
      "0    102011028     Avoca Beach - Copacabana    643.8000        7590   \n",
      "1    102011029  Box Head - MacMasters Beach   3208.6000       10986   \n",
      "2    102011030              Calga - Kulnura  76795.1000        4841   \n",
      "3    102011031          Erina - Green Point   3379.3000       14237   \n",
      "4    102011032        Gosford - Springfield   1691.2000       19385   \n",
      "..         ...                          ...         ...         ...   \n",
      "317  106011109              Cessnock Region   1570.4341        7931   \n",
      "318  106011113             Singleton Region   4067.2349        4919   \n",
      "319  111021218        Morisset - Cooranbong    330.5208       14959   \n",
      "320  114021285         Hill Top - Colo Vale    174.3752        6025   \n",
      "321  114021289           Southern Highlands   1409.7013        6589   \n",
      "\n",
      "     number_of_dwellings  number_of_businesses  \\\n",
      "0                   2325                 738.0   \n",
      "1                   3847                 907.0   \n",
      "2                   1575                1102.0   \n",
      "3                   4450                1666.0   \n",
      "4                   6373                2126.0   \n",
      "..                   ...                   ...   \n",
      "317                 3281                 673.0   \n",
      "318                 2055                 698.0   \n",
      "319                 6298                1154.0   \n",
      "320                 2249                 400.0   \n",
      "321                 3405                 856.0   \n",
      "\n",
      "     median_annual_household_income  avg_monthly_rent  \n",
      "0                           46996.0            1906.0  \n",
      "1                           42621.0            1682.0  \n",
      "2                           42105.0            1182.0  \n",
      "3                           43481.0            1595.0  \n",
      "4                           45972.0            1382.0  \n",
      "..                              ...               ...  \n",
      "317                         73164.0            1080.0  \n",
      "318                         87984.0            1000.0  \n",
      "319                         58084.0            1260.0  \n",
      "320                         81120.0            1512.0  \n",
      "321                         65572.0            1200.0  \n",
      "\n",
      "[309 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "rawData = pd.read_csv(\"Neighbourhoods.csv\")\n",
    "#Check if there's null values\n",
    "\n",
    "noNull_data = checkNull(rawData)\n",
    "neighbourhoods_clean = noNull_data.copy()\n",
    "numericData = ['area_id', 'land_area', 'population', 'number_of_dwellings', 'number_of_dwellings', \n",
    "               'number_of_businesses', 'median_annual_household_income', 'avg_monthly_rent']\n",
    "\n",
    "for col in noNull_data.columns:\n",
    "    \n",
    "    if col in numericData:        \n",
    "        if noNull_data[col].dtypes != int and noNull_data[col].dtypes != float:\n",
    "            neighbourhoods_clean[col] = noNull_data[col].str.replace(',', '')\n",
    "            neighbourhoods_clean[col] = pd.to_numeric(neighbourhoods_clean[col])   \n",
    "            \n",
    "print (\"\\nCommas in numeric data removed and all numbers as type string converted to numeric values!\")\n",
    "\n",
    "print(neighbourhoods_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Uploading BusinessStats.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No null values in. Good to go, no need for cleaning :)\n",
      "\n",
      "Commas in numeric data removed and all numbers as type string converted to numeric values!\n",
      "Created table for business stats\n"
     ]
    }
   ],
   "source": [
    "rawData = pd.read_csv(\"BusinessStats.csv\")\n",
    "\n",
    "#Remove null values\n",
    "noNull_data = checkNull(rawData)\n",
    "businesStats_clean = noNull_data.copy()\n",
    "\n",
    "numericData = ['area_id', 'number_of_businesses', 'accommodation_and_food_services', 'retail_trade', 'agriculture_forestry_and_fishing', \n",
    "               'health_care_and_social_assistance', 'public_administration_and_safety', 'transport_postal_and_warehousing']\n",
    "\n",
    "for col in noNull_data.columns:\n",
    "    \n",
    "    if col in numericData:        \n",
    "        if noNull_data[col].dtypes != int and noNull_data[col].dtypes != float:\n",
    "            businesStats_clean[col] = noNull_data[col].str.replace(',', '')\n",
    "            businesStats_clean[col] = pd.to_numeric(businesStats_clean[col])   \n",
    "\n",
    "            \n",
    "print (\"\\nCommas in numeric data removed and all numbers as type string converted to numeric values!\")\n",
    "\n",
    "print(businesStats_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Uploading RFSNSW_BFPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_pathname = os.path.abspath(\"RFSNSW_BFPL.shp\")\n",
    "rfs_shapefile = gpd.read_file(abs_pathname)\n",
    "rfs_shapefile = checkNull(rfs_shapefile)\n",
    "\n",
    "print(rfs_shapefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Uploading SA2_2016_AUST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SA2_MAIN16 SA2_5DIG16                            SA2_NAME16 SA3_CODE16  \\\n",
      "0     101021007      11007                             Braidwood      10102   \n",
      "1     101021008      11008                               Karabar      10102   \n",
      "2     101021009      11009                            Queanbeyan      10102   \n",
      "3     101021010      11010                     Queanbeyan - East      10102   \n",
      "4     101021011      11011                     Queanbeyan Region      10102   \n",
      "...         ...        ...                                   ...        ...   \n",
      "2305  901021002      91002               Cocos (Keeling) Islands      90102   \n",
      "2306  901031003      91003                            Jervis Bay      90103   \n",
      "2307  901041004      91004                        Norfolk Island      90104   \n",
      "2308  997979799      99799  Migratory - Offshore - Shipping (OT)      99797   \n",
      "2309  999999499      99499                 No usual address (OT)      99999   \n",
      "\n",
      "                                SA3_NAME16 SA4_CODE16  \\\n",
      "0                               Queanbeyan        101   \n",
      "1                               Queanbeyan        101   \n",
      "2                               Queanbeyan        101   \n",
      "3                               Queanbeyan        101   \n",
      "4                               Queanbeyan        101   \n",
      "...                                    ...        ...   \n",
      "2305               Cocos (Keeling) Islands        901   \n",
      "2306                            Jervis Bay        901   \n",
      "2307                        Norfolk Island        901   \n",
      "2308  Migratory - Offshore - Shipping (OT)        997   \n",
      "2309                 No usual address (OT)        999   \n",
      "\n",
      "                                SA4_NAME16 GCC_CODE16  \\\n",
      "0                           Capital Region      1RNSW   \n",
      "1                           Capital Region      1RNSW   \n",
      "2                           Capital Region      1RNSW   \n",
      "3                           Capital Region      1RNSW   \n",
      "4                           Capital Region      1RNSW   \n",
      "...                                    ...        ...   \n",
      "2305                     Other Territories      9OTER   \n",
      "2306                     Other Territories      9OTER   \n",
      "2307                     Other Territories      9OTER   \n",
      "2308  Migratory - Offshore - Shipping (OT)      99799   \n",
      "2309                 No usual address (OT)      99499   \n",
      "\n",
      "                                GCC_NAME16 STE_CODE16         STE_NAME16  \\\n",
      "0                              Rest of NSW          1    New South Wales   \n",
      "1                              Rest of NSW          1    New South Wales   \n",
      "2                              Rest of NSW          1    New South Wales   \n",
      "3                              Rest of NSW          1    New South Wales   \n",
      "4                              Rest of NSW          1    New South Wales   \n",
      "...                                    ...        ...                ...   \n",
      "2305                     Other Territories          9  Other Territories   \n",
      "2306                     Other Territories          9  Other Territories   \n",
      "2307                     Other Territories          9  Other Territories   \n",
      "2308  Migratory - Offshore - Shipping (OT)          9  Other Territories   \n",
      "2309                 No usual address (OT)          9  Other Territories   \n",
      "\n",
      "      AREASQKM16                                           geometry  \n",
      "0      3418.3525  POLYGON ((149.58423 -35.44427, 149.58444 -35.4...  \n",
      "1         6.9825  POLYGON ((149.21898 -35.36739, 149.21799 -35.3...  \n",
      "2         4.7634  POLYGON ((149.21325 -35.34325, 149.21619 -35.3...  \n",
      "3        13.0034  POLYGON ((149.24033 -35.34782, 149.24023 -35.3...  \n",
      "4      3054.4099  POLYGON ((149.23580 -35.38738, 149.23771 -35.3...  \n",
      "...          ...                                                ...  \n",
      "2305     13.7163  MULTIPOLYGON (((96.83047 -12.17636, 96.83045 -...  \n",
      "2306     67.8134  MULTIPOLYGON (((150.69566 -35.18297, 150.69555...  \n",
      "2307     38.6509  MULTIPOLYGON (((167.99472 -29.04534, 167.99432...  \n",
      "2308      0.0000                                               None  \n",
      "2309      0.0000                                               None  \n",
      "\n",
      "[2310 rows x 13 columns]\n",
      "THIS DATASET HAS SOME NA VALUES.\n",
      "Null value found. Coverted null values to ...\n",
      "\n",
      "Null values have been removed. You're good to go!\n",
      "SA2_MAIN16      object\n",
      "SA2_5DIG16      object\n",
      "SA2_NAME16      object\n",
      "SA3_CODE16      object\n",
      "SA3_NAME16      object\n",
      "SA4_CODE16      object\n",
      "SA4_NAME16      object\n",
      "GCC_CODE16      object\n",
      "GCC_NAME16      object\n",
      "STE_CODE16      object\n",
      "STE_NAME16      object\n",
      "AREASQKM16     float64\n",
      "geometry      geometry\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "abs_pathname = os.path.abspath(\"SA2_2016_AUST.shp\")\n",
    "sa_2_shapefile = gpd.read_file(abs_pathname)\n",
    "print(sa_2_shapefile)\n",
    "sa_2_shapefile = checkNull(sa_2_shapefile)\n",
    "print(sa_2_shapefile.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Uploading Additional Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the json file\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "\n",
    "with open('RFSStation_EPSG4326.json') as f:\n",
    "  fire_stations = json.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "i = 0\n",
    "data_length = len(fire_stations['RFSStation']['features'])\n",
    "null_found = False\n",
    "\n",
    "while i < data_length:\n",
    "    if len(fire_stations['RFSStation']['features'][i]['geometry']['coordinates']) < 2:\n",
    "        print(\"Null coordinates found\")\n",
    "        null_found = True\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "if not null_found:\n",
    "    print(\"No Null Coordinates in this file. You're good to go!\")\n",
    "    \n",
    "fireStation_df = gpd.GeoDataFrame.from_features(fire_stations['RFSStation'])\n",
    "fireStation_df.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining the Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to join the three CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = pd.read_sql_query(\"SELECT * FROM neighbourhoods\",conn)\n",
    "one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two = pd.read_sql_query(\"SELECT population, land_area, population/land_area AS population_density FROM neighbourhoods\",conn)\n",
    "two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three = pd.read_sql_query(\"SELECT number_of_dwellings, land_area FROM neighbourhoods\",conn)\n",
    "three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four = pd.read_sql_query(\"SELECT number_of_dwellings, land_area, number_of_dwellings/land_area AS dwelling_density FROM neighbourhoods\",conn)\n",
    "four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five = pd.read_sql_query(\"SELECT * FROM businessstats\",conn)\n",
    "five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Three Way Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "six = pd.read_sql_query(\"SELECT * FROM businessstats B, neighbourhoods N, statisticalareas S WHERE B.area_id = S.area_id AND S.area_id = N.area_id\",conn)\n",
    "six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seven = pd.read_sql_query(\"\"\"SELECT N.population/N.land_area AS population_density,\n",
    "                                    N.number_of_dwellings/N.land_area AS dwelling_density,\n",
    "                                    B.number_of_businesses/N.land_area AS business_density,\n",
    "                                    B.health_care_and_social_assistance/N.land_area AS assistive_service_density\n",
    "                            FROM businessstats B, neighbourhoods N, statisticalareas S \n",
    "                            WHERE B.area_id = S.area_id \n",
    "                            AND S.area_id = N.area_id\n",
    "                           \n",
    "                          \"\"\"\n",
    "                          ,conn)\n",
    "seven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's refer to the shape file now since we're nearly there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfs_shapefile = rfs_shapefile.set_crs(epsg=4326,allow_override=True )\n",
    "sa_2_shapefile = sa_2_shapefile.set_crs(epsg=4326,allow_override=True )\n",
    "\n",
    "rfs_sa2 = gpd.sjoin(sa_2_shapefile, rfs_shapefile, op='contains')\n",
    "rfs_sa2_frame = rfs_sa2['SA2_MAIN16'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fireStation_df = fireStation_df.set_crs(epsg=4326,allow_override=True )\n",
    "\n",
    "#Searching for points that is within the land specified\n",
    "fireStation_sa2 = gpd.sjoin(fireStation_df, sa_2_shapefile, op='within')\n",
    "fireStation_sa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fireStation_count = fireStation_sa2.groupby(['SA2_MAIN16']).count()\n",
    "fireStation_count = fireStation_count['geometry'].to_frame()\n",
    "fireStation_count['SA2_MAIN16_fireS'] = fireStation_count.index\n",
    "fireStation_count = fireStation_count.rename(columns={'geometry': 'station_count'})\n",
    "\n",
    "\n",
    "firestations_count_val = \"\"\"CREATE TABLE IF NOT EXISTS firestations (\n",
    "                        SA2_MAIN16 Integer PRIMARY KEY,\n",
    "                        station_count Integer\n",
    "                   )\"\"\"\n",
    "\n",
    "conn.execute(firestations_count_val)\n",
    "fireStation_count.to_sql('firestations', con=conn, if_exists='replace',index=False)\n",
    "res = pd.read_sql_query('SELECT * FROM firestations', conn)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfs_sa2_frame = rfs_sa2.merge(fireStation_count, on=\"SA2_MAIN16\")\n",
    "rfs_sa2_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
