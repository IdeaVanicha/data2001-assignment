{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from geoalchemy2 import Geometry, WKTElement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Uploading Data to pgAdmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the section below, we are cleaning all our files including:\n",
    "1.  Neighbourhoods.csv\n",
    "2.  BusinessStats.csv\n",
    "3.  StatisticalAreas.csv\n",
    "4.  RFSNSW_BFPL.shp\n",
    "5.  SA2_2016_AUST.shp\n",
    "6.  RFSStation_EPSG4326.json (additional dataset)\n",
    "\n",
    "Methods for cleaning data includes:\n",
    "\n",
    "- checkNull(dataset, beenCleaned): check if there's a null value\n",
    "- removeNull(dataset): drop the null value in the dataset\n",
    "\n",
    "** For each dataset, we also check the type of different columns to see if they are in their correct type. If they're not, then we convert them. For instance, all population values are intially string, but we convert them into numeric values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function use to check if null values exist in the dataset. If there's null value, we'll drop the row to increase \n",
    "# accuracy in our calculations.\n",
    "\n",
    "def checkNull( dataset ):\n",
    "    \n",
    "    beenCleaned = False    \n",
    "    \n",
    "    for num in list(dataset.isnull().sum()):\n",
    "\n",
    "        if num != 0:\n",
    "            print(\"THIS DATASET HAS SOME NA VALUES.\")\n",
    "            print(\"Null value found. Coverted null values to ...\")\n",
    "            dataset = dataset.dropna() #found null, drop the row\n",
    "            beenCleaned = True\n",
    "            \n",
    "    if beenCleaned:\n",
    "        print(\"\\nNull values have been removed. You're good to go!\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nNo null values in. Good to go, no need for cleaning :)\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected\n"
     ]
    }
   ],
   "source": [
    "#Connecting to pgAdmin\n",
    "\n",
    "data_path = \".\"\n",
    "\n",
    "def pgconnect(credential_filepath, db_schema=\"public\"):\n",
    "    with open(credential_filepath) as f:\n",
    "        db_conn_dict = json.load(f)\n",
    "        HOST       = db_conn_dict['host']\n",
    "        DB_USER    = db_conn_dict['user']\n",
    "        DB_PW      = db_conn_dict['password']\n",
    "        DEFAULT_DB = db_conn_dict['user']\n",
    "\n",
    "        try:\n",
    "            db = create_engine('postgres+psycopg2://'+DB_USER+':'+DB_PW+'@'+HOST+'/'+DEFAULT_DB, echo=False)\n",
    "            conn = db.connect()\n",
    "            print('connected')\n",
    "        except Exception as e:\n",
    "            print(\"unable to connect to the database\")\n",
    "            print(e)\n",
    "            \n",
    "        return db,conn\n",
    "\n",
    "credfilepath = os.path.join(data_path, \"data2x01_db.json\")\n",
    "db, conn = pgconnect(credfilepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning StatisticalAreas.csv and Uploading it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No null values in. Good to go, no need for cleaning :)\n",
      "\n",
      "Successfully, created table for statistical areas...\n",
      "\n",
      "Uploaded clean statistical areas data to pgAdmin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_id</th>\n",
       "      <th>area_name</th>\n",
       "      <th>parent_area_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Greater Sydney</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>Rest of NSW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>Greater Melbourne</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>106</td>\n",
       "      <td>Hunter Valley exc Newcastle</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>11102</td>\n",
       "      <td>Lake Macquarie - West</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>111</td>\n",
       "      <td>Newcastle and Lake Macquarie</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>11402</td>\n",
       "      <td>Southern Highlands</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>114</td>\n",
       "      <td>Southern Highlands and Shoalhaven</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     area_id                          area_name  parent_area_id\n",
       "0          1                    New South Wales               0\n",
       "1         10                     Greater Sydney               1\n",
       "2         11                        Rest of NSW               1\n",
       "3          2                           Victoria               0\n",
       "4         20                  Greater Melbourne               2\n",
       "..       ...                                ...             ...\n",
       "429      106        Hunter Valley exc Newcastle              11\n",
       "430    11102              Lake Macquarie - West             111\n",
       "431      111       Newcastle and Lake Macquarie              11\n",
       "432    11402                 Southern Highlands             114\n",
       "433      114  Southern Highlands and Shoalhaven              11\n",
       "\n",
       "[434 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData = pd.read_csv(\"StatisticalAreas.csv\")\n",
    "\n",
    "#Check if contains NULL\n",
    "cleanData = checkNull(rawData)\n",
    "\n",
    "#Cleaning data so that only numeric values are included in area_id\n",
    "if cleanData['area_id'].dtypes != int:\n",
    "    print(\"\\nUpdated area_id data type from \" + str(cleanData['area_id'].dtypes) + \" to integer & removed data with wrong type\")\n",
    "    cleanData = cleanData[cleanData.area_id.str.isnumeric()]\n",
    "    cleanData['area_id'].astype(int)\n",
    "\n",
    "#Cleaning data so that only numeric values are included in parent_area_id\n",
    "if cleanData['parent_area_id'].dtypes != int:\n",
    "    print(\"\\nUpdated area_id data type from \" + str(cleanData['parent_area_id'].dtypes) + \" to integer & removed data with wrong type\")\n",
    "    cleanData = cleanData[cleanData.parent_area_id.str.isnumeric()]\n",
    "    cleanData['parent_area_id'].astype(int)\n",
    "\n",
    "statisticalAreas_clean = cleanData\n",
    "\n",
    "#Uploading StatisticalAreas.csv to pgAdmin\n",
    "\n",
    "conn.execute(\"DROP TABLE IF EXISTS statisticalareas\")\n",
    "\n",
    "statistical_areas = \"\"\"CREATE TABLE IF NOT EXISTS statisticalareas (\n",
    "                         area_id   Integer PRIMARY KEY,\n",
    "                         area_name VARCHAR(20),\n",
    "                         parent_area_id Integer\n",
    "                   )\"\"\"\n",
    "conn.execute(statistical_areas)\n",
    "print(\"\\nSuccessfully, created table for statistical areas...\")\n",
    "\n",
    "table_name = \"statisticalareas\"\n",
    "statisticalAreas_clean.to_sql(table_name, con=conn, if_exists='replace',index=False)\n",
    "print (\"\\nUploaded clean statistical areas data to pgAdmin\")\n",
    "res = pd.read_sql_query(\"SELECT * FROM statisticalareas\",conn)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Uploading Neighbourhoods.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS DATASET HAS SOME NA VALUES.\n",
      "Null value found. Coverted null values to ...\n",
      "THIS DATASET HAS SOME NA VALUES.\n",
      "Null value found. Coverted null values to ...\n",
      "THIS DATASET HAS SOME NA VALUES.\n",
      "Null value found. Coverted null values to ...\n",
      "THIS DATASET HAS SOME NA VALUES.\n",
      "Null value found. Coverted null values to ...\n",
      "\n",
      "Null values have been removed. You're good to go!\n",
      "\n",
      "Commas in numeric data removed and all numbers as type string converted to numeric values!\n",
      "\n",
      "Successfully created neighbourhoods table.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_id</th>\n",
       "      <th>area_name</th>\n",
       "      <th>land_area</th>\n",
       "      <th>population</th>\n",
       "      <th>number_of_dwellings</th>\n",
       "      <th>number_of_businesses</th>\n",
       "      <th>median_annual_household_income</th>\n",
       "      <th>avg_monthly_rent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102011028</td>\n",
       "      <td>Avoca Beach - Copacabana</td>\n",
       "      <td>643.8000</td>\n",
       "      <td>7590</td>\n",
       "      <td>2325</td>\n",
       "      <td>738.0</td>\n",
       "      <td>46996.0</td>\n",
       "      <td>1906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102011029</td>\n",
       "      <td>Box Head - MacMasters Beach</td>\n",
       "      <td>3208.6000</td>\n",
       "      <td>10986</td>\n",
       "      <td>3847</td>\n",
       "      <td>907.0</td>\n",
       "      <td>42621.0</td>\n",
       "      <td>1682.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102011030</td>\n",
       "      <td>Calga - Kulnura</td>\n",
       "      <td>76795.1000</td>\n",
       "      <td>4841</td>\n",
       "      <td>1575</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>42105.0</td>\n",
       "      <td>1182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102011031</td>\n",
       "      <td>Erina - Green Point</td>\n",
       "      <td>3379.3000</td>\n",
       "      <td>14237</td>\n",
       "      <td>4450</td>\n",
       "      <td>1666.0</td>\n",
       "      <td>43481.0</td>\n",
       "      <td>1595.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102011032</td>\n",
       "      <td>Gosford - Springfield</td>\n",
       "      <td>1691.2000</td>\n",
       "      <td>19385</td>\n",
       "      <td>6373</td>\n",
       "      <td>2126.0</td>\n",
       "      <td>45972.0</td>\n",
       "      <td>1382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>106011109</td>\n",
       "      <td>Cessnock Region</td>\n",
       "      <td>1570.4341</td>\n",
       "      <td>7931</td>\n",
       "      <td>3281</td>\n",
       "      <td>673.0</td>\n",
       "      <td>73164.0</td>\n",
       "      <td>1080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>106011113</td>\n",
       "      <td>Singleton Region</td>\n",
       "      <td>4067.2349</td>\n",
       "      <td>4919</td>\n",
       "      <td>2055</td>\n",
       "      <td>698.0</td>\n",
       "      <td>87984.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>111021218</td>\n",
       "      <td>Morisset - Cooranbong</td>\n",
       "      <td>330.5208</td>\n",
       "      <td>14959</td>\n",
       "      <td>6298</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>58084.0</td>\n",
       "      <td>1260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>114021285</td>\n",
       "      <td>Hill Top - Colo Vale</td>\n",
       "      <td>174.3752</td>\n",
       "      <td>6025</td>\n",
       "      <td>2249</td>\n",
       "      <td>400.0</td>\n",
       "      <td>81120.0</td>\n",
       "      <td>1512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>114021289</td>\n",
       "      <td>Southern Highlands</td>\n",
       "      <td>1409.7013</td>\n",
       "      <td>6589</td>\n",
       "      <td>3405</td>\n",
       "      <td>856.0</td>\n",
       "      <td>65572.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       area_id                    area_name   land_area  population  \\\n",
       "0    102011028     Avoca Beach - Copacabana    643.8000        7590   \n",
       "1    102011029  Box Head - MacMasters Beach   3208.6000       10986   \n",
       "2    102011030              Calga - Kulnura  76795.1000        4841   \n",
       "3    102011031          Erina - Green Point   3379.3000       14237   \n",
       "4    102011032        Gosford - Springfield   1691.2000       19385   \n",
       "..         ...                          ...         ...         ...   \n",
       "304  106011109              Cessnock Region   1570.4341        7931   \n",
       "305  106011113             Singleton Region   4067.2349        4919   \n",
       "306  111021218        Morisset - Cooranbong    330.5208       14959   \n",
       "307  114021285         Hill Top - Colo Vale    174.3752        6025   \n",
       "308  114021289           Southern Highlands   1409.7013        6589   \n",
       "\n",
       "     number_of_dwellings  number_of_businesses  \\\n",
       "0                   2325                 738.0   \n",
       "1                   3847                 907.0   \n",
       "2                   1575                1102.0   \n",
       "3                   4450                1666.0   \n",
       "4                   6373                2126.0   \n",
       "..                   ...                   ...   \n",
       "304                 3281                 673.0   \n",
       "305                 2055                 698.0   \n",
       "306                 6298                1154.0   \n",
       "307                 2249                 400.0   \n",
       "308                 3405                 856.0   \n",
       "\n",
       "     median_annual_household_income  avg_monthly_rent  \n",
       "0                           46996.0            1906.0  \n",
       "1                           42621.0            1682.0  \n",
       "2                           42105.0            1182.0  \n",
       "3                           43481.0            1595.0  \n",
       "4                           45972.0            1382.0  \n",
       "..                              ...               ...  \n",
       "304                         73164.0            1080.0  \n",
       "305                         87984.0            1000.0  \n",
       "306                         58084.0            1260.0  \n",
       "307                         81120.0            1512.0  \n",
       "308                         65572.0            1200.0  \n",
       "\n",
       "[309 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData = pd.read_csv(\"Neighbourhoods.csv\")\n",
    "#Check if there's null values\n",
    "\n",
    "noNull_data = checkNull(rawData)\n",
    "neighbourhoods_clean = noNull_data.copy()\n",
    "numericData = ['area_id', 'land_area', 'population', 'number_of_dwellings', 'number_of_dwellings', \n",
    "               'number_of_businesses', 'median_annual_household_income', 'avg_monthly_rent']\n",
    "\n",
    "for col in noNull_data.columns:\n",
    "    \n",
    "    if col in numericData:        \n",
    "        if noNull_data[col].dtypes != int and noNull_data[col].dtypes != float:\n",
    "            neighbourhoods_clean[col] = noNull_data[col].str.replace(',', '')\n",
    "            neighbourhoods_clean[col] = pd.to_numeric(neighbourhoods_clean[col])   \n",
    "            \n",
    "print (\"\\nCommas in numeric data removed and all numbers as type string converted to numeric values!\")\n",
    "\n",
    "#Uploading Neighbourhoods.csv to pgAdmin\n",
    "\n",
    "conn.execute(\"DROP TABLE IF EXISTS neighbourhoods\")\n",
    "\n",
    "neighbourhoods = \"\"\"CREATE TABLE IF NOT EXISTS neighbourhoods (\n",
    "                         area_id   Integer PRIMARY KEY,\n",
    "                         area_name VARCHAR(20),\n",
    "                         land_area Integer,\n",
    "                         population Integer,\n",
    "                         number_of_dwellings Integer,\n",
    "                         number_of_businesses Integer,\n",
    "                         median_annual_household_income Integer,\n",
    "                         avg_monthly_rent Integer\n",
    "                   )\"\"\"\n",
    "conn.execute(neighbourhoods)\n",
    "print(\"\\nSuccessfully created neighbourhoods table.\")\n",
    "\n",
    "#Testing if table has been created\n",
    "table_name = \"neighbourhoods\"\n",
    "neighbourhoods_clean.to_sql(table_name, con=conn, if_exists='replace',index=False)\n",
    "\n",
    "res = pd.read_sql_query('SELECT * FROM neighbourhoods', conn)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Uploading BusinessStats.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No null values in. Good to go, no need for cleaning :)\n",
      "\n",
      "Commas in numeric data removed and all numbers as type string converted to numeric values!\n",
      "Created table for business stats\n"
     ]
    }
   ],
   "source": [
    "rawData = pd.read_csv(\"BusinessStats.csv\")\n",
    "\n",
    "#Remove null values\n",
    "noNull_data = checkNull(rawData)\n",
    "businesStats_clean = noNull_data.copy()\n",
    "\n",
    "numericData = ['area_id', 'number_of_businesses', 'accommodation_and_food_services', 'retail_trade', 'agriculture_forestry_and_fishing', \n",
    "               'health_care_and_social_assistance', 'public_administration_and_safety', 'transport_postal_and_warehousing']\n",
    "\n",
    "for col in noNull_data.columns:\n",
    "    \n",
    "    if col in numericData:        \n",
    "        if noNull_data[col].dtypes != int and noNull_data[col].dtypes != float:\n",
    "            businesStats_clean[col] = noNull_data[col].str.replace(',', '')\n",
    "            businesStats_clean[col] = pd.to_numeric(businesStats_clean[col])   \n",
    "\n",
    "            \n",
    "print (\"\\nCommas in numeric data removed and all numbers as type string converted to numeric values!\")\n",
    "\n",
    "conn.execute(\"DROP TABLE IF EXISTS businessstats\")\n",
    "\n",
    "business_stats = \"\"\"CREATE TABLE IF NOT EXISTS businessstats (\n",
    "                         area_id   Integer PRIMARY KEY,\n",
    "                         area_name VARCHAR(20),\n",
    "                         number_of_businesses Integer,\n",
    "                         accomodation_and_food_services Integer,\n",
    "                         retail_trade Integer,\n",
    "                         agriculture_forestry_and_fishing Integer,\n",
    "                         health_care_and_social_assistance Integer,\n",
    "                         public_administration_and_safety Integer,\n",
    "                         transport_postal_and_warehousing Integer\n",
    "                   )\"\"\"\n",
    "conn.execute(business_stats)\n",
    "print(\"Created table for business stats\")\n",
    "\n",
    "table_name = \"businessstats\"\n",
    "businesStats_clean.to_sql(table_name, con=conn, if_exists='replace',index=False)\n",
    "\n",
    "#Testing if table has been created\n",
    "print (\"Business Stats table created\")\n",
    "res = pd.read_sql_query('SELECT * FROM businessstats', conn)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Uploading RFSNSW_BFPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_pathname = os.path.abspath(\"RFSNSW_BFPL.shp\")\n",
    "rfs_shapefile = gpd.read_file(abs_pathname)\n",
    "print(rfs_shapefile)\n",
    "rfs_shapefile = checkNull(rfs_shapefile)\n",
    "\n",
    "\n",
    "RFSNSW_BFPL = '''CREATE TABLE rfsnsw_bfpl (\n",
    "                     \"CATEGORY\" INTEGER, \n",
    "                     \"SHAPE_LENG\" FLOAT, \n",
    "                     \"SHAPE_AREA\" FLOAT, \n",
    "                     location GEOMETRY(POINT,4326))''' \n",
    "\n",
    "conn.execute(\"DROP TABLE IF EXISTS rfsnsw_bfpl\")\n",
    "conn.execute(RFSNSW_BFPL)\n",
    "\n",
    "rfs_tablename = \"rfsnsw_bfpl\"\n",
    "rfs_shapefile.to_postgis(rfs_tablename, conn, if_exists='replace')\n",
    "\n",
    "res = pd.read_sql_query('SELECT * FROM rfsnsw_bfpl', conn)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Uploading SA2_2016_AUST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_pathname = os.path.abspath(\"SA2_2016_AUST.shp\")\n",
    "sa_2_shapefile = gpd.read_file(abs_pathname)\n",
    "print(sa_2_shapefile)\n",
    "sa_2_shapefile = checkNull(sa_2_shapefile)\n",
    "print(sa_2_shapefile.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA2_2016 = '''CREATE TABLE sa2_2016 (\n",
    "                     \"SA2_MAIN16\" NUMERIC, \n",
    "                     \"SA2_5DIG16\" NUMERIC, \n",
    "                     \"SA2_NAME16\" VARCHAR(50), \n",
    "                     \"SA3_CODE16\" NUMERIC, \n",
    "                     \"SA3_NAME16\" VARCHAR(50), \n",
    "                     \"SA4_CODE16\" NUMERIC,\n",
    "                     \"SA4_NAME16\" VARCHAR(50), \n",
    "                     \"GCC_CODE16\" VARCHAR(50), \n",
    "                     \"GCC_NAME16\" VARCHAR(50),\n",
    "                     \"STE_CODE16\" NUMERIC, \n",
    "                     \"STE_NAME16\" VARCHAR(50), \n",
    "                     \"AREASQKM16\" FLOAT,\n",
    "                     location GEOMETRY(MULTIPOLYGON,4326))''' \n",
    "\n",
    "conn.execute(\"DROP TABLE IF EXISTS sa2_2016\")\n",
    "conn.execute(SA2_2016)\n",
    "\n",
    "sa2_tablename = \"sa2_2016\"\n",
    "sa_2_shapefile.to_postgis(sa2_tablename, conn, if_exists='replace')\n",
    "\n",
    "res = pd.read_sql_query('SELECT * FROM sa2_2016', conn)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Uploading Additional Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the json file\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "\n",
    "with open('RFSStation_EPSG4326.json') as f:\n",
    "  fire_stations = json.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "i = 0\n",
    "data_length = len(fire_stations['RFSStation']['features'])\n",
    "null_found = False\n",
    "\n",
    "while i < data_length:\n",
    "    if len(fire_stations['RFSStation']['features'][i]['geometry']['coordinates']) < 2:\n",
    "        print(\"Null coordinates found\")\n",
    "        null_found = True\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "if not null_found:\n",
    "    print(\"No Null Coordinates in this file. You're good to go!\")\n",
    "    \n",
    "fireStation_df = gpd.GeoDataFrame.from_features(fire_stations['RFSStation'])\n",
    "fireStation_df.plot()\n",
    "\n",
    "#Creating table for firestations\n",
    "conn.execute(\"DROP TABLE IF EXISTS rfsfirestations\")\n",
    "\n",
    "RFS_FireStations = \"\"\"CREATE TABLE IF NOT EXISTS rfsfirestations (\n",
    "                        coordinates GEOMETRY PRIMARY KEY,\n",
    "                        stationid INTEGER, \n",
    "                        station_name VARCHAR(20)\n",
    "                   )\"\"\"\n",
    "\n",
    "try:\n",
    "     conn.execute(RFS_FireStations)\n",
    "     print(\"Successfully created table for fire_stations\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(\"Table not created.\\n\")\n",
    "     print(e)\n",
    "    \n",
    "fireStation_df.to_postgis('rfsfirestations', conn, if_exists='replace')\n",
    "res = pd.read_sql_query('SELECT * FROM rfsfirestations', conn)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining the Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to join the three CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = pd.read_sql_query(\"SELECT * FROM neighbourhoods\",conn)\n",
    "one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two = pd.read_sql_query(\"SELECT population, land_area, population/land_area AS population_density FROM neighbourhoods\",conn)\n",
    "two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three = pd.read_sql_query(\"SELECT number_of_dwellings, land_area FROM neighbourhoods\",conn)\n",
    "three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four = pd.read_sql_query(\"SELECT number_of_dwellings, land_area, number_of_dwellings/land_area AS dwelling_density FROM neighbourhoods\",conn)\n",
    "four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five = pd.read_sql_query(\"SELECT * FROM businessstats\",conn)\n",
    "five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Three Way Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "six = pd.read_sql_query(\"SELECT * FROM businessstats B, neighbourhoods N, statisticalareas S WHERE B.area_id = S.area_id AND S.area_id = N.area_id\",conn)\n",
    "six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seven = pd.read_sql_query(\"\"\"SELECT N.population/N.land_area AS population_density,\n",
    "                                    N.number_of_dwellings/N.land_area AS dwelling_density,\n",
    "                                    B.number_of_businesses/N.land_area AS business_density,\n",
    "                                    B.health_care_and_social_assistance/N.land_area AS assistive_service_density\n",
    "                            FROM businessstats B, neighbourhoods N, statisticalareas S \n",
    "                            WHERE B.area_id = S.area_id \n",
    "                            AND S.area_id = N.area_id\n",
    "                           \n",
    "                          \"\"\"\n",
    "                          ,conn)\n",
    "seven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's refer to the shape file now since we're nearly there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfs_shapefile = rfs_shapefile.set_crs(epsg=4326,allow_override=True )\n",
    "sa_2_shapefile = sa_2_shapefile.set_crs(epsg=4326,allow_override=True )\n",
    "\n",
    "rfs_sa2 = gpd.sjoin(sa_2_shapefile, rfs_shapefile, op='contains')\n",
    "rfs_sa2_frame = rfs_sa2['SA2_MAIN16'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fireStation_df = fireStation_df.set_crs(epsg=4326,allow_override=True )\n",
    "\n",
    "#Searching for points that is within the land specified\n",
    "fireStation_sa2 = gpd.sjoin(fireStation_df, sa_2_shapefile, op='within')\n",
    "fireStation_sa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fireStation_count = fireStation_sa2.groupby(['SA2_MAIN16']).count()\n",
    "fireStation_count = fireStation_count['geometry'].to_frame()\n",
    "fireStation_count['SA2_MAIN16_fireS'] = fireStation_count.index\n",
    "fireStation_count = fireStation_count.rename(columns={'geometry': 'station_count'})\n",
    "\n",
    "\n",
    "firestations_count_val = \"\"\"CREATE TABLE IF NOT EXISTS firestations (\n",
    "                        SA2_MAIN16 Integer PRIMARY KEY,\n",
    "                        station_count Integer\n",
    "                   )\"\"\"\n",
    "\n",
    "conn.execute(firestations_count_val)\n",
    "fireStation_count.to_sql('firestations', con=conn, if_exists='replace',index=False)\n",
    "res = pd.read_sql_query('SELECT * FROM firestations', conn)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfs_sa2_frame = rfs_sa2.merge(fireStation_count, on=\"SA2_MAIN16\")\n",
    "rfs_sa2_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
